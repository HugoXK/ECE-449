{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pytorch flow](https://cdn-images-1.medium.com/max/800/1*uZrS4KjAuSJQIJPgOiaJUg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.317551Z",
     "iopub.status.busy": "2021-11-14T11:06:31.317222Z",
     "iopub.status.idle": "2021-11-14T11:06:31.325556Z",
     "shell.execute_reply": "2021-11-14T11:06:31.324577Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.317497Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.329742Z",
     "iopub.status.busy": "2021-11-14T11:06:31.329298Z",
     "iopub.status.idle": "2021-11-14T11:06:31.344115Z",
     "shell.execute_reply": "2021-11-14T11:06:31.343260Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.329699Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model1 = True\n",
    "run_model2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.346822Z",
     "iopub.status.busy": "2021-11-14T11:06:31.346138Z",
     "iopub.status.idle": "2021-11-14T11:06:31.356902Z",
     "shell.execute_reply": "2021-11-14T11:06:31.356245Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.346426Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cifar10_data(filename):\n",
    "    with open('../input/cifar10/'+ filename, 'rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    features = batch['data']\n",
    "    labels = batch['labels']\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.358931Z",
     "iopub.status.busy": "2021-11-14T11:06:31.358291Z",
     "iopub.status.idle": "2021-11-14T11:06:31.665264Z",
     "shell.execute_reply": "2021-11-14T11:06:31.664297Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.358872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "batch_1, labels_1 = load_cifar10_data('data_batch_1')\n",
    "batch_2, labels_2 = load_cifar10_data('data_batch_2')\n",
    "batch_3, labels_3 = load_cifar10_data('data_batch_3')\n",
    "batch_4, labels_4 = load_cifar10_data('data_batch_4')\n",
    "batch_5, labels_5 = load_cifar10_data('data_batch_5')\n",
    "\n",
    "test, label_test = load_cifar10_data('test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.667363Z",
     "iopub.status.busy": "2021-11-14T11:06:31.666885Z",
     "iopub.status.idle": "2021-11-14T11:06:31.804126Z",
     "shell.execute_reply": "2021-11-14T11:06:31.803234Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.667273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge files\n",
    "X_train = np.concatenate([batch_1,batch_2,batch_3,batch_4,batch_5], 0)\n",
    "Y_train = np.concatenate([labels_1,labels_2,labels_3,labels_4,labels_5], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.805693Z",
     "iopub.status.busy": "2021-11-14T11:06:31.805416Z",
     "iopub.status.idle": "2021-11-14T11:06:31.811694Z",
     "shell.execute_reply": "2021-11-14T11:06:31.811001Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.805635Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = ('airplane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def return_photo(batch_file):\n",
    "    assert batch_file.shape[1] == 3072\n",
    "    dim = np.sqrt(1024).astype(int)\n",
    "    r = batch_file[:, 0:1024].reshape(batch_file.shape[0], dim, dim, 1)\n",
    "    g = batch_file[:, 1024:2048].reshape(batch_file.shape[0], dim, dim, 1)\n",
    "    b = batch_file[:, 2048:3072].reshape(batch_file.shape[0], dim, dim, 1)\n",
    "    photo = np.concatenate([r,g,b], -1)\n",
    "    return photo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:31.813174Z",
     "iopub.status.busy": "2021-11-14T11:06:31.812744Z",
     "iopub.status.idle": "2021-11-14T11:06:32.067426Z",
     "shell.execute_reply": "2021-11-14T11:06:32.066538Z",
     "shell.execute_reply.started": "2021-11-14T11:06:31.813115Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = return_photo(X_train)\n",
    "X_test = return_photo(test)\n",
    "Y_test = np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:32.068941Z",
     "iopub.status.busy": "2021-11-14T11:06:32.068530Z",
     "iopub.status.idle": "2021-11-14T11:06:32.277970Z",
     "shell.execute_reply": "2021-11-14T11:06:32.276984Z",
     "shell.execute_reply.started": "2021-11-14T11:06:32.068881Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_image(number, file, label, pred=None):\n",
    "    fig = plt.figure(figsize = (3,2))\n",
    "    #img = return_photo(batch_file)\n",
    "    plt.imshow(file[number])\n",
    "    if pred is None:\n",
    "        plt.title(classes[label[number]])\n",
    "    else:\n",
    "        plt.title('Label_true: ' + classes[label[number]] + '\\nLabel_pred: ' + classes[pred[number]])\n",
    "    \n",
    "plot_image(12345, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:32.280184Z",
     "iopub.status.busy": "2021-11-14T11:06:32.279551Z",
     "iopub.status.idle": "2021-11-14T11:06:33.013393Z",
     "shell.execute_reply": "2021-11-14T11:06:33.012329Z",
     "shell.execute_reply.started": "2021-11-14T11:06:32.280111Z"
    }
   },
   "outputs": [],
   "source": [
    "# The cifar-10 is designed to balance distribution that the counts for each classification are 5000\n",
    "import seaborn as sns\n",
    "sns.countplot(Y_train)\n",
    "hist_Y_train = pd.Series(Y_train).groupby(Y_train).count()\n",
    "print(hist_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:33.015735Z",
     "iopub.status.busy": "2021-11-14T11:06:33.015159Z",
     "iopub.status.idle": "2021-11-14T11:06:33.025476Z",
     "shell.execute_reply": "2021-11-14T11:06:33.024387Z",
     "shell.execute_reply.started": "2021-11-14T11:06:33.015669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final check for dimensions before pre-pocessing\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:33.029553Z",
     "iopub.status.busy": "2021-11-14T11:06:33.028489Z",
     "iopub.status.idle": "2021-11-14T11:06:33.353611Z",
     "shell.execute_reply": "2021-11-14T11:06:33.352538Z",
     "shell.execute_reply.started": "2021-11-14T11:06:33.029168Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the validation set out\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:33.355339Z",
     "iopub.status.busy": "2021-11-14T11:06:33.355065Z",
     "iopub.status.idle": "2021-11-14T11:06:33.642824Z",
     "shell.execute_reply": "2021-11-14T11:06:33.642113Z",
     "shell.execute_reply.started": "2021-11-14T11:06:33.355285Z"
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "### Prepare for training & testing dataset. Define dataset class.\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "# define the random seed for reproducible result\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "class CIFAR10_from_array(Dataset): \n",
    "    def __init__(self, data, label, transform=None):\n",
    "        ##############################################\n",
    "        ### Initialize paths, transforms, and so on\n",
    "        ##############################################\n",
    "        #self.data = torch.from_numpy(data).float()\n",
    "        #self.label = torch.from_numpy(label).long()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.img_shape = data.shape\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ##############################################\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        ##############################################\n",
    "        \n",
    "        img = Image.fromarray(self.data[index])\n",
    "        label = self.label[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img_to_tensor = transforms.ToTensor()\n",
    "            img = img_to_tensor(img)\n",
    "            #label = torch.from_numpy(label).long()\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        ##############################################\n",
    "        ### Indicate the total size of the dataset\n",
    "        ##############################################\n",
    "        return len(self.data)\n",
    "    \n",
    "    def plot_image(self, number):\n",
    "        file = self.data\n",
    "        label = self.label\n",
    "        fig = plt.figure(figsize = (3,2))\n",
    "        #img = return_photo(batch_file)\n",
    "        plt.imshow(file[number])\n",
    "        plt.title(classes[label[number]])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:33.644467Z",
     "iopub.status.busy": "2021-11-14T11:06:33.644127Z",
     "iopub.status.idle": "2021-11-14T11:06:33.649470Z",
     "shell.execute_reply": "2021-11-14T11:06:33.648354Z",
     "shell.execute_reply.started": "2021-11-14T11:06:33.644402Z"
    }
   },
   "outputs": [],
   "source": [
    "class CIFAR10_from_url(Dataset): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:33.651444Z",
     "iopub.status.busy": "2021-11-14T11:06:33.651099Z",
     "iopub.status.idle": "2021-11-14T11:06:44.816726Z",
     "shell.execute_reply": "2021-11-14T11:06:44.815891Z",
     "shell.execute_reply.started": "2021-11-14T11:06:33.651379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize for R, G, B with img = img - mean / std\n",
    "def normalize_dataset(data):\n",
    "    mean = data.mean(axis=(0,1,2)) / 255.0\n",
    "    std = data.std(axis=(0,1,2)) / 255.0\n",
    "    normalize = transforms.Normalize(mean=mean, std=std)\n",
    "    return normalize\n",
    "\n",
    "\n",
    "# \n",
    "train_transform_aug = transforms.Compose([\n",
    "###\n",
    "#insert your code here  \n",
    "#implement some data augmentation methods here\n",
    "#for example, transforms.Resize((40, 40)),\n",
    "    \n",
    "###\n",
    "    transforms.Resize((40, 40)),       #First adjust to a slightly larger image\n",
    "    transforms.RandomCrop((32, 32)),   #Then randomly extract to the size of the model input\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_dataset(X_train)\n",
    "\n",
    "])\n",
    "\n",
    "# Also use X_train in normalize since train/val sets should have same distribution\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_dataset(X_train)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_dataset(X_test)\n",
    "])\n",
    "\n",
    "trainset = CIFAR10_from_array(data=X_train_split, label=Y_train_split, transform=train_transform_aug)\n",
    "valset = CIFAR10_from_array(data=X_val_split, label=Y_val_split, transform=val_transform)\n",
    "testset = CIFAR10_from_array(data=X_test, label=Y_test, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.818574Z",
     "iopub.status.busy": "2021-11-14T11:06:44.818206Z",
     "iopub.status.idle": "2021-11-14T11:06:44.838431Z",
     "shell.execute_reply": "2021-11-14T11:06:44.837505Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.818508Z"
    }
   },
   "outputs": [],
   "source": [
    "print('data shape check')\n",
    "print('training set:'.ljust(20) + '{}'.format(trainset.img_shape))\n",
    "print('validation set:'.ljust(20) + '{}'.format(valset.img_shape))\n",
    "print('testing set:'.ljust(20) + '{}'.format(testset.img_shape))\n",
    "print('label numbers:'.ljust(20) + '{}'.format(len(set(trainset.label))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.840089Z",
     "iopub.status.busy": "2021-11-14T11:06:44.839826Z",
     "iopub.status.idle": "2021-11-14T11:06:44.849579Z",
     "shell.execute_reply": "2021-11-14T11:06:44.848753Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.840044Z"
    }
   },
   "outputs": [],
   "source": [
    "# put into the data loader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 1\n",
    "\n",
    "train_loader = DataLoader(dataset=trainset,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "\n",
    "val_loader = DataLoader(dataset=valset,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "test_loader = DataLoader(dataset=testset,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.851431Z",
     "iopub.status.busy": "2021-11-14T11:06:44.851082Z",
     "iopub.status.idle": "2021-11-14T11:06:44.962668Z",
     "shell.execute_reply": "2021-11-14T11:06:44.961138Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.851360Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs, lbls = iter(train_loader).next()\n",
    "print ('Size of image:', imgs.size())  # batch_size*3*224*224\n",
    "print ('Type of image:', imgs.dtype)   # float32\n",
    "print ('Size of label:', lbls.size())  # batch_size\n",
    "print ('Type of label:', lbls.dtype)   # int64(long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "### Model with out augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.964943Z",
     "iopub.status.busy": "2021-11-14T11:06:44.964489Z",
     "iopub.status.idle": "2021-11-14T11:06:44.970659Z",
     "shell.execute_reply": "2021-11-14T11:06:44.969631Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.964868Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.972320Z",
     "iopub.status.busy": "2021-11-14T11:06:44.971982Z",
     "iopub.status.idle": "2021-11-14T11:06:44.983469Z",
     "shell.execute_reply": "2021-11-14T11:06:44.982498Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.972262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "class Net(nn.Module):\n",
    "        #implement your own network here\n",
    "        #you can use any simple CNN structure learned from class\n",
    "        #for example, LeNet\n",
    "        \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:44.985009Z",
     "iopub.status.busy": "2021-11-14T11:06:44.984706Z",
     "iopub.status.idle": "2021-11-14T11:06:45.009364Z",
     "shell.execute_reply": "2021-11-14T11:06:45.008272Z",
     "shell.execute_reply.started": "2021-11-14T11:06:44.984899Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model training\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def update_info(idx, length, epoch_loss, acc, mode):\n",
    "    \n",
    "    if length >= 250:\n",
    "        update_size = int(length/250)\n",
    "    else:\n",
    "        update_size = 5\n",
    "    \n",
    "    if idx % update_size == 0 and idx != 0:\n",
    "        #print ('=', end=\"\")        \n",
    "        finish_rate = idx/length * 100\n",
    "        print (\"\\r   {} progress: {:.2f}%  ......  loss: {:.4f} , acc: {:.4f}\".\n",
    "               format(mode, finish_rate, epoch_loss/idx, acc), end=\"\", flush=True)\n",
    "        \n",
    "\n",
    "def val_per_epoch(model, loss_fn, dataloader, verbose):\n",
    "    # In validation, we only compute loss value\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    acc = 0.0\n",
    "    val_size = 0\n",
    "    with torch.no_grad(): \n",
    "        for i, (feature, target) in enumerate(dataloader):\n",
    "            \n",
    "            #feature, target = feature.to(device), target.to(device)\n",
    "            if torch.cuda.is_available():\n",
    "                feature = feature.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            output = model(feature) #outputs.data.shape= batches_num * num_class\n",
    "            \n",
    "            #compute acc\n",
    "            _, pred = torch.max(output.data, dim=1) \n",
    "            correct = (pred == target).sum().item() #convert to number\n",
    "            val_size += target.size(0)\n",
    "            acc += correct\n",
    "            \n",
    "            \n",
    "            loss = loss_fn(output, target)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            idx = i\n",
    "            length = len(dataloader)\n",
    "            \n",
    "            #display progress\n",
    "            if verbose:\n",
    "                update_info(idx, length, epoch_loss, acc/val_size, 'validating')\n",
    "                \n",
    "        acc = acc/val_size\n",
    "    print('')\n",
    "    return epoch_loss/len(dataloader), acc\n",
    "\n",
    "\n",
    "def train_per_epoch(model, loss_fn, dataloader, optimizer, verbose): \n",
    "    #train mode\n",
    "    model.train()\n",
    "    \n",
    "    #initialize loss\n",
    "    epoch_loss = 0.0\n",
    "    acc = 0.0\n",
    "    train_size = 0\n",
    "    \n",
    "    for i, (feature, target) in enumerate(dataloader):\n",
    "        #feature, target = feature.to(device), target.to(device)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            feature = feature.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        #set zero to the parameter gradients for initialization\n",
    "        optimizer.zero_grad()\n",
    "        output = model(feature)\n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        \n",
    "        #compute acc\n",
    "        _, pred = torch.max(output.data, dim=1) \n",
    "        correct = (pred == target).sum().item() #convert to number\n",
    "        train_size += target.size(0)\n",
    "        acc += correct\n",
    "        \n",
    "        #compute current loss. Loss is a 0-dim tensor, so use tensor.item() to get the scalar value\n",
    "        epoch_loss += loss.item()  \n",
    "        \n",
    "        #backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #this represents one update on the weight/bias for a mini-batch(16 images in our case): \n",
    "        #weights[k] + alpha * d_weights[k]\n",
    "        optimizer.step()\n",
    "        \n",
    "        #show the update information\n",
    "        idx = i\n",
    "        length = len(dataloader)\n",
    "        \n",
    "        #display progress\n",
    "        if verbose:\n",
    "            update_info(idx, length, epoch_loss, acc/train_size, '  training')\n",
    "            \n",
    "    acc = acc/train_size\n",
    "    print('') \n",
    "    return epoch_loss/len(dataloader), acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_training(num_epochs, model, loss_fn, train_loader, optimizer, val_loader=None, verbose=True):\n",
    "    \n",
    "    train_batch_num = len(train_loader)\n",
    "    history = {}\n",
    "    history['train_loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['train_acc'] = []\n",
    "    history['val_acc'] = []\n",
    "    \n",
    "    if val_loader is not None:\n",
    "        \n",
    "        val_batch_num = len(val_loader)\n",
    "        \n",
    "        print('Total Sample: Train on {} samples, validate on {} samples.'.\n",
    "             format(trainset.img_shape[0], valset.img_shape[0]))\n",
    "        \n",
    "        print(' Total Batch: Train on {} batches, validate on {} batches. {} samples/minibatch \\n'.\n",
    "         format(train_batch_num, val_batch_num, batch_size))\n",
    "    \n",
    "    else:\n",
    "        print('Total Sample: Train on {} samples.'.\n",
    "             format(train_batch_num*batch_size))\n",
    "        \n",
    "        print(' Total Batch: Train on {} batches, {} samples/minibatch \\n'.\n",
    "         format(train_batch_num, batch_size))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        train_loss, train_acc = train_per_epoch(model, loss_fn, train_loader, optimizer, verbose=verbose)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        \n",
    "        \n",
    "        if val_loader is not None:\n",
    "            val_loss, val_acc = val_per_epoch(model, loss_fn, val_loader, verbose=verbose)\n",
    "            print('\\n        Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(train_loss,val_loss))\n",
    "            print('         Training acc: {:.4f},  Validation acc: {:.4f}\\n'.format(train_acc,val_acc))\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "                        \n",
    "        else:\n",
    "            print('\\n        Training Loss: {:.4f}\\n'.format(train_loss))\n",
    "            print('\\n         Training acc: {:.4f}\\n'.format(train_acc))\n",
    "        \n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:06:45.011631Z",
     "iopub.status.busy": "2021-11-14T11:06:45.011208Z",
     "iopub.status.idle": "2021-11-14T11:10:32.420153Z",
     "shell.execute_reply": "2021-11-14T11:10:32.419340Z",
     "shell.execute_reply.started": "2021-11-14T11:06:45.011561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training/Validating the model\n",
    "classes = ('airplane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def lr_decay(parm):\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__' and run_model1 == True:\n",
    "\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    net = Net()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    print(net)\n",
    "    print('=================================================================')\n",
    "\n",
    "    #insert your code here\n",
    "    #implement criterion(also known as loss funtion) and optimizer here\n",
    "    #we suggest you to use CrossEntropyLoss and Adam\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() #loss function\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "\n",
    "    #training and validating\n",
    "    hist1 = model_training(num_epochs, net, criterion, train_loader, optimizer, val_loader, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:32.422078Z",
     "iopub.status.busy": "2021-11-14T11:10:32.421582Z",
     "iopub.status.idle": "2021-11-14T11:10:43.267079Z",
     "shell.execute_reply": "2021-11-14T11:10:43.265845Z",
     "shell.execute_reply.started": "2021-11-14T11:10:32.422030Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img    # unnormalize\n",
    "    #print(img)\n",
    "    npimg = img.numpy()\n",
    "    print(np.transpose(npimg, (1, 2, 0)).shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__' and run_model1 == True:\n",
    "    dataiter = iter(test_loader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        plot_image(i, images.permute(0, 2, 3, 1).numpy(), labels.numpy())\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        images = images.cuda()\n",
    "    outputs = net(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                                  for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:43.270013Z",
     "iopub.status.busy": "2021-11-14T11:10:43.269337Z",
     "iopub.status.idle": "2021-11-14T11:10:46.148235Z",
     "shell.execute_reply": "2021-11-14T11:10:46.147213Z",
     "shell.execute_reply.started": "2021-11-14T11:10:43.269927Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_testing(model, loss_fn, dataloader, verbose=True):\n",
    "    Y_pred = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0.0\n",
    "    acc = 0.0\n",
    "    test_size = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (feature, target) in enumerate(dataloader):\n",
    "            if torch.cuda.is_available():\n",
    "                feature = feature.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            outputs = model(feature)  #outputs.data.shape= batches_num * num_class\n",
    "            \n",
    "            #compute acc\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            correct = (pred == target).sum().item() #convert to number\n",
    "            test_size += target.size(0)\n",
    "            #print(test_size)\n",
    "            acc += correct\n",
    "            \n",
    "            loss = loss_fn(outputs, target)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            idx = i\n",
    "            length = len(dataloader)\n",
    "\n",
    "\n",
    "            #if torch.cuda.is_available():\n",
    "            #    pred = pred.cuda()\n",
    "            \n",
    "            #Pred labels \n",
    "            Y_pred += pred.cpu().numpy().tolist()\n",
    "            \n",
    "            if verbose:\n",
    "                update_info(idx, length, epoch_loss, acc/test_size, 'testing')    \n",
    "            \n",
    "    acc = acc/test_size\n",
    "    print('\\n\\n Accuracy of the network on the {} test images: {}%'.format(test_size, 100*acc))\n",
    "    \n",
    "    return Y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and run_model1 == True:\n",
    "    Y_pred1 = model_testing(net, criterion, test_loader, True)\n",
    "    \n",
    "if __name__ == '__main__' and run_model2 == True:\n",
    "    Y_pred2 = model_testing(net, criterion, test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:46.150519Z",
     "iopub.status.busy": "2021-11-14T11:10:46.150221Z",
     "iopub.status.idle": "2021-11-14T11:10:46.157162Z",
     "shell.execute_reply": "2021-11-14T11:10:46.156415Z",
     "shell.execute_reply.started": "2021-11-14T11:10:46.150467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "def loss_acc_plt(history):\n",
    "    fig, ax = plt.subplots(2,1)\n",
    "    ax[0].plot(history['train_loss'], color='b', label=\"Training loss\")\n",
    "    ax[0].plot(history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history['train_acc'], color='b', label=\"Training accuracy\")\n",
    "    ax[1].plot(history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:46.158871Z",
     "iopub.status.busy": "2021-11-14T11:10:46.158613Z",
     "iopub.status.idle": "2021-11-14T11:10:46.662674Z",
     "shell.execute_reply": "2021-11-14T11:10:46.661296Z",
     "shell.execute_reply.started": "2021-11-14T11:10:46.158818Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and run_model1 == True:\n",
    "    loss_acc_plt(hist1)\n",
    "    \n",
    "if __name__ == '__main__' and run_model2 == True:\n",
    "    loss_acc_plt(hist2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:46.665425Z",
     "iopub.status.busy": "2021-11-14T11:10:46.664842Z",
     "iopub.status.idle": "2021-11-14T11:10:48.748219Z",
     "shell.execute_reply": "2021-11-14T11:10:48.747181Z",
     "shell.execute_reply.started": "2021-11-14T11:10:46.665180Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and run_model1 == True:\n",
    "    for i in range(10):\n",
    "        plot_image(i, test_loader.dataset.data, test_loader.dataset.label, Y_pred1)\n",
    "    \n",
    "if __name__ == '__main__' and run_model2 == True:\n",
    "    for i in range(10):\n",
    "        plot_image(i, test_loader.dataset.data, test_loader.dataset.label, Y_pred2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:48.751066Z",
     "iopub.status.busy": "2021-11-14T11:10:48.750109Z",
     "iopub.status.idle": "2021-11-14T11:10:48.815071Z",
     "shell.execute_reply": "2021-11-14T11:10:48.814112Z",
     "shell.execute_reply.started": "2021-11-14T11:10:48.750981Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and run_model1 == True:\n",
    "    cm = confusion_matrix(Y_test, Y_pred1)\n",
    "\n",
    "if __name__ == '__main__' and run_model2 == True:\n",
    "    cm = confusion_matrix(Y_test, Y_pred2)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:10:48.817622Z",
     "iopub.status.busy": "2021-11-14T11:10:48.816933Z",
     "iopub.status.idle": "2021-11-14T11:10:49.917222Z",
     "shell.execute_reply": "2021-11-14T11:10:49.916063Z",
     "shell.execute_reply.started": "2021-11-14T11:10:48.817554Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.colorbar()\n",
    "n_classes = cm.shape[0]\n",
    "range_class = range(n_classes)\n",
    "tick_marks = np.arange(len(range_class))\n",
    "plt.xticks(tick_marks, range_class, rotation=-45, fontsize=14)\n",
    "plt.yticks(tick_marks, range_class, fontsize=14)\n",
    "plt.xlabel('Predicted label', fontsize=14)\n",
    "plt.ylabel('True label', fontsize=14)\n",
    "\n",
    "for i in range_class:\n",
    "    for j in range_class:        \n",
    "        plt.text(j, i, cm[i,j], horizontalalignment=\"center\", fontsize=14, \n",
    "                color=\"white\" if i==j else \"black\")\n",
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-14T11:14:00.905829Z",
     "iopub.status.busy": "2021-11-14T11:14:00.905138Z",
     "iopub.status.idle": "2021-11-14T11:14:00.941593Z",
     "shell.execute_reply": "2021-11-14T11:14:00.940643Z",
     "shell.execute_reply.started": "2021-11-14T11:14:00.905777Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    correct = ((Y_test == i)*1) * ((np.array(Y_pred1) == Y_test)*1)\n",
    "    print('{}, {}: '.rjust(10).format(i, classes[i]) + '{}%'.\n",
    "          format(100*correct.sum()/Y_test[Y_test == i].shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
